# very deep convolutional networks for large-scale image recognition

Description: VGG19
Journal/Conference: IEEE
Year: 2015
작성일: 2021년 3월 2일
작성자: 익명
태그: CNN, Computer Vision, Neural Network

# Abstruct

본 연구에서는 대규모 이미지 인식 설정에서 컨볼루션 네트워크 깊이가 정확도에 미치는 영향을 조사한다. 우리의 주된 기여는 매우 작은(3×3) 컨볼루션 필터를 사용하는 아키텍처를 사용하여 깊이가 증가하는 네트워크를 철저히 평가하는 것으로, 이는 깊이를 16–19 중량 레이어로 밀어냄으로써 이전 기술 구성에 대한 상당한 개선이 달성될 수 있음을 보여준다. 이러한 발견은 ImageNet Challenge 2014 제출의 기초가 되었으며, 각 팀은 현지화와 분류 트랙에서 1위와 2위를 확보했다. 또한 우리의 표현이 다른 데이터 세트에 잘 일반화되어 최첨단 결과를 달성한다는 것을 보여준다. 우리는 컴퓨터 비전에서의 심층 시각적 표현 사용에 대한 추가 연구를 용이하게 하기 위해 가장 성능이 우수한 ConvNet 모델 두 개를 공개적으로 사용할 수 있도록 했다.

컨볼루션 네트워크(ConvNets)는 최근 ImageNet과 같은 대규모 공개 이미지 저장소와 GPU 또는 대규모 분산 클러스터와 같은 고성능 컴퓨팅 시스템으로 인해 가능해진 대규모 이미지 및 비디오 인식에서 큰 성공을 거두고 있다(Dean et al., 2012). 특히, 심층 시각적 인식 아키텍처의 발전에서 중요한 역할은 고차원 얕은 특징 인코딩에서 심층 ConvNet에 이르기까지 몇 세대에 걸친 대규모 이미지 분류 시스템의 테스트 베드 역할을 해온 ImageNet Large-Scale Visual Recognition Challenge(ILSVRC)에 의해 수행되었다.

ConvNets가 컴퓨터 비전 분야에서 더 많은 상품이 되면서, 더 나은 정확도를 달성하기 위해 Krizhevsky 등(2012)의 원래 아키텍처를 개선하려는 많은 시도가 이루어졌다. 예를 들어 ILSVRC-2013(Zeiler & Fergus, 2013; Sermanet al., 2014)에 대한 최고 성능의 제출물은 첫 번째 컨볼루션 계층의 더 작은 수용 창 크기와 더 작은 보폭을 활용했다. 또 다른 개선 사항에서는 전체 이미지와 여러 규모에 걸쳐 네트워크를 조밀하게 훈련하고 테스트하는 문제를 다뤘습니다(Sermanet 등, 2014; Howard, 2014). 본 논문에서는 ConvNet 아키텍처 설계의 또 다른 중요한 측면, 즉 깊이를 다룬다. 이를 위해 아키텍처의 다른 매개 변수를 수정하고, 모든 계층에서 매우 작은(3 × 3) 컨볼루션 필터를 사용하기 때문에 실현 가능한 컨볼루션 레이어를 추가하여 네트워크의 깊이를 꾸준히 증가시킨다.

그 결과, 우리는 ILSVRC 분류 및 현지화 작업에서 최첨단 정확도를 달성할 뿐만 아니라, 비교적 단순한 파이프라인의 일부로 사용해도 우수한 성능을 달성하는 다른 이미지 인식 데이터 세트에도 적용할 수 있는 훨씬 더 정확한 ConvNet 아키텍처를 고안한다. 미세 조정되지 않은 선형 SVM으로 분류됩니다. 우리는 추가 연구를 용이하게 하기 위해 가장 성능이 좋은 두 가지 모델 1을 출시했다.

그 논문의 나머지 부분은 다음과 같이 정리되어 있다. 섹션 2에서는 ConvNet 구성에 대해 설명합니다. 그런 다음 이미지 분류 훈련과 평가의 세부사항이 제3장에 제시되고, 구성은 제4장의 ILSVRC 분류 과제에서 비교된다. 제5장이 논문을 마무리한다. 또한 완전성을 위해 부록 A의 ILSVRC-2014 객체 현지화 시스템을 설명하고 평가하고 부록 B의 다른 데이터 세트에 대한 매우 심층적인 기능의 일반화에 대해 논의한다. 마지막으로, 부록 C에는 주요 논문 개정 목록이 포함되어 있습니다.

# 인스트럭션을 읽고 논문에 대한 질문 적기

- 층을 깊게 쌓으면 파라미터가 많아져서, 파라미터 바꿔주면서 실험할 때 어떤 파라미터가 결정적인지 알기까지 많은 실험을 했을거같은데 그런게 뒤에 나오나?
- 실험 도표로 제공됨, 몇번쨰 실험때 파라미터 뭐고 이런거까지는 아니고 층이 늘어날수록 파라미터가 줄어든다고 함
- 알렉넷(레이어 8개)에 비해 2배 많은 층, 학습에 걸리는 시간은 얼마나 늘었을까, 연산처리에 걸리는 시간은 어떻게 극복했을까

# 백그라운드 읽은 후, 5문장 이내로 요약하기

- 구조 요약 (3줄 컨피그레이션~아키텍쳐 ) :

vgg 16의 경우, 13 Convolution Layers + 3 Fully-connected Layers, 3x3 convolution filters, stride: 1 & padding: 1, 2x2 max pooling (stride : 2), ReLU, 인풋 이미지는 224x224로 고정하고 알쥐비 평균 밸류를 빼줌. 레이어를 11부터 19까지 쌓음

- 의미 요약(2줄 디스커션) :

첫번째로는 Stride가 1일 때, 3차례의 3x3 Conv 필터링을 반복한 특징맵은 한 픽셀이 원본 이미지의 7x7 Receptive field의 효과를 볼 수 있다. – 결정 함수의 비선형성 증가

: 더많은 활성화 함수 사용하여 렐루 더많이 사용가능

두번째로는 더 많은 컨볼류션레이어를 사용하는 것인 학습 파라미터 수의 감소시킴 그래서 오버피팅을 방지할 수 있음

# 어프로치 단계 정리하기

# 메소드 부분 모델이나 아키텍쳐 장표에 나만의 코멘트 기록하기

- Depth의 단위는 어디서 어디까지지?

(하나의 컨브층과 맥스풀링 층의 세트가 한 단위인가- 아님 그냥 딱 컨브층만임)

- 왜 더 층을 19이상을 쌓지 않을까 – 논문에 따르면 뎁스가 늘어나면 파라미터도 줄어든다고 했는데
1. 익스페리먼트 정리하기(방법은 어떤 방법인지, 데이터 셋 구조, 실험 방법)
- 분류 실험 : 데이터 셋은 이미지넷 라지 스케일 리코그니션 데이터

ILSVRC는 이미지넷(ImageNet)이 제공하는 1,000여 카테고리로 분류된 100만 개의 이미지(트레이닝:1백3십만 / 검증 5만 / 테스트 10만)

실험 방법 – 1. 싱글 스케일 이발류에이션 : 테스트 시 이미지 사이즈 고정된 것, 트레이닝 이미지 사이즈를 256이나 384로 고정 시켜주는 방식

- 로컬 리스폰스 노멀라이제이션한 것과 안 한 거 성능 차이없음
- 1 바이 1 필터보다 3바이 3 필터가 더 좋은 성능 – 삼바이삼이 이미지의 위치정보를 더 잘 추출해주기때문
1. 멀티 스케일 트레이닝 : **Multi-scale**: 다양한 크기의 이미지를 학습하는 모델을 만들기 위해 고려한 방법

256 ~ 512의 이미지 사이즈로 크기를 조정하고 224의 고정 크기로 잘라 학습함. 하나의 이미지 사이즈에 대해 여러 스케일로 학습하는 데이터 증식의 역할

위의 S값은 Training Data에서의 값이며, 여기서 사용되는 Q는 S와 정의가 같지만 Testing Data에 대한 값이다. ImageNet의 데이터는 1000개의 클래스로 이루어져 있고 각각 1000개 씩의 이미지로 이루어져 있는데, 이는 충분히 많은 데이터라고 볼 수 없으므로 Testing Data에 대한 Augmentation을 시도했다. 먼저 이미지 하나를 여러 개의 Q 값으로 Augmentation한 뒤, 네트워크에 넣어 각각의 결과값을 얻어내고, 이를 평균(Sum-Pooling)내어 최종 분류 결과를 구한다. 또한 각 이미지를 Horizontal하게 뒤집은 데이터도 테스팅에 사용했다. 

1. 멀티 크롭 이발류에이션과 컨브넷 퓨전

Evaluation은 두 가지 방식을 적용했다. 먼저 첫번째 Fully-Connected Layer를 7x7 Conv Layer로 변환시킨 뒤 원본 이미지를 투입하는 방식을 취하며 OverFeat 논문(Sermanet et al., 2014)에서 사용된 **Dense Evaluation이**다. 이것의 장점은 AlexNet에서처럼 테스팅 시에 데이터를 Multiple Crop하는 과정을 제거할 수 있기 때문에 효율적인 연산이 가능하다는 것이다.  또한 GoogLeNet에서 사용된 **Multi-crop Evaluation**도 적용해 Dense Evaluation과 상호보완적인 시너지를 내게 만들었다. 세부내용에 대해서는 각 논문을 참고하면 된다.

- 덴스 이발류에이션 방식과 멀티 크롭 이발류에이션 방식을 비교
- 멀티 크롭 방식과 덴스 이발류에이션의 평균을 통해 두 방식을 섞은 새로운 방식 = 컨브넷 퓨전 – 이게 결과가 좋다 몇으로

결과적으로 구글넷에 비해 굉장히 간결한 구조를 가지면서도 좋은 성능을 보임

신경망의 깊이의 유효성을 증명했다

네 개의 NVIDIA Titan Black GPU를 사용했음에도 네트워크 하나를 학습시키는데 2~3주가 걸렸다는 비효율의 문제

# 논문과 관련된 다른 논문이 어떤 것이 있는지, 논문 제목 및 정보 적기

- 구글 넷 인셉션 (going deeper with convolutions)- 그해 vgg넷과 같이 참여해서 1등, vgg는 2등  르넷 – 너무 옛날거

레스넷 - Deep Residual Learning for Image Recognition

================================================================논문 리뷰중 오간 내용

1. 이미지넷 데이터 봐보기
2. 가중치 수치의 높낮이는 학습과 상관없음 
개수가 많으면 → 학습시간이 늘어남
3. 컨볼루션 필터 사이즈가 늘어나면 → 파라미터 개수가 늘어남
레이어 수가 늘어나면 → 파라미터의 개수가 늘어나는 것은 아님
4. FCL: 값의 위치를 보정해주기위한 과정 
- 앞에서 쪼개진 conv, max의 값
- 클래스 개수를 맞춰주기 위한 것. 뜯어보면 클래스 개수와 FCN의 노드 개수 동일
1. 3x3 필터 여러개쓰면 문제에 유연하게 대처(XOR) / 1x1쓰면 유연하게 대처 불가 
그래서 16이나 19나 비슷
2. FCL(일정한 크기)대신 conv layer(인풋의 크기 제약없음) 쓰면 히트맵spn(어떤 클래스인지)가능, FC만 쓰면 수치 확률만 출력
3. 고정 - 사람이 주는 풀링방법은 파라미터 없음
조정- 기계가 스스로 하는 게 파라미터 조정
층- 노드가 존재해야하는데 풀링,렐루는 노드가 없음 그래서 층도 없음 → FC와 conv만 레이어로 개수 카운트하느것임
4. 검증 
- 싱글 스케일 : 학습과 검증이 같은 스케일(이미지 사이즈)
- 멀티 스케일: 학습과 검증이 다른 스케일 → 성능이 싱글보다 좋다
1. 구글넷 vgg lenet resnet 모두 그래디언트 배니싱 해결하기위한 모델들임. 나중에 통합됨(인셉션 레스넷)